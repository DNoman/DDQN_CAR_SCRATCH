{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a5fe73",
   "metadata": {
    "id": "74a5fe73"
   },
   "source": [
    "# Maze Harvest\n",
    "\n",
    " Maze Harvest is an environment where an agent is placed in a 2D grid with randomly spawning fruits. The agent can collect two types of fruits, red fruits which have a power of 10, and green fruits which have a power of 5. \n",
    " \n",
    " If the agent does not have down syndrome, when it consumes a red fruit it can grow its body size up to the floor value of (X+Y)/2, where X and Y are the shape of the 2D grid.\n",
    "\n",
    "The agent has limited visibility and can only see the fruits and walls within a window of n units in four directions - up, down, left, and right. However, the agent has the ability to smell the fruits over the grid in these directions: front left, front right, back left & back right (Like four Venn diagrams, each intersecting with two adjacent sets but not center). \n",
    "\n",
    "\n",
    "The goal of the agent is to eat as many fruits as possible and to survive the maze.\n",
    "\n",
    "### Environment and its limits\n",
    "> $Avg = \\lfloor (X+Y)/2 \\rfloor$\n",
    "\n",
    "\n",
    "- Environment size limit: $10\\le X,Y \\le 50$, if not under limit size set to 10\n",
    "- Maximum Fruit Spawn: $Avg$\n",
    "- Number of Walls: limit $\\le 30\\%$ of the total cells ($20 - 25\\%$ is the best range)\n",
    "- Maximum Body size: $Avg$\n",
    "- Default Maximum Moves Alloweded: 10000 (we can change it)\n",
    "- Action Space: 4, 0 left, 1 up, 2 right, 3 down.\n",
    "- Default Window Size: 10, window size should be less than or equal to $Avg$, or else default will be used.\n",
    "- During reset, we can set the wall proportion and enable or disable down syndrome(nds - no down syndrome), default 0.25 and falls.\n",
    "- State Size 16, One hot encoded direction (4), Danger and Food (8) each 4 directions, Smell of fruits (4).\n",
    "\n",
    "### Reward System\n",
    "- default $0 \\to Reward$\n",
    "- if agent hit body or wall or max moves reached $-10 \\to Reward$\n",
    "- else if agent ate a fruit $10*power + Reward \\to Reward$\n",
    "- then the reward poisoned by powers of fruits already in the environment $(Reward - \\frac {1}{10}\\sum^F_i power_i)  \\to Reward$\n",
    "\n",
    "- If it reaches maximum moves or, body or wall hit, the game is done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c2a01",
   "metadata": {},
   "source": [
    "\n",
    "**File:** `maze_harvest.py`\n",
    "- `Environment`: Initialize new environment with given parameters.\n",
    "- `play_frames`: Require lamda function to clear shell, input: recorded frames.\n",
    "    - play frames example: `play_frames(frames,lambda : clear_output(wait=True),sleep=0.3)`\n",
    "    \n",
    " - **Utils**:\n",
    "     - Class: `ActionSpace`.\n",
    "     - Functions: `euclidean`,`gaussian_kernel` & `nxt_direction`\n",
    "     - Variables: `color_map` & `directions`\n",
    "     \n",
    " **File:** `dqn_tf.py`\n",
    "  - `DQN`: Requires Architecture & Activation Functions (other parameters are set to default values)\n",
    "  - **Utils**:\n",
    "      - Classes: `ReplayMemory` & `QNetwork`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48011868",
   "metadata": {
    "id": "48011868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BAO DAT\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from maze_harvest import Environment, play_frames\n",
    "from dqn_tf import DQN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9141f71",
   "metadata": {
    "id": "d9141f71"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "def play(net,env,slow=0.1,walls=.2,nds=False,record=False,print_now=True):\n",
    "    nxt_state = env.reset(walls=walls,nds=nds)\n",
    "    done = False\n",
    "    if record: env.record(True)\n",
    "    env.render(print_now)\n",
    "    while not done:\n",
    "        state = nxt_state\n",
    "        sleep(slow)\n",
    "        action = np.argmax(net(np.array([state])))\n",
    "        nxt_state,r,done = env.step(action)\n",
    "        clear_output(wait=True)\n",
    "        env.render(print_now)\n",
    "    \n",
    "    if record:\n",
    "        return env.record(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b7e68b",
   "metadata": {
    "id": "14b7e68b"
   },
   "outputs": [],
   "source": [
    "def train(agent,env,num_episodes=100,batch_size=32,C=100,ep=10,walls=.2,nds=False):\n",
    "    steps=0\n",
    "    for i in range(1,num_episodes+1):\n",
    "        try:\n",
    "            episode_loss = 0\n",
    "            t = 0\n",
    "\n",
    "            # Sample Phase\n",
    "            agent.decay_epsilon()\n",
    "            nxt_state = env.reset(walls=walls,nds=nds)\n",
    "            done = False\n",
    "            while not done:\n",
    "                state = nxt_state\n",
    "                action = agent.e_greedy(state,env)\n",
    "                nxt_state,reward,done = env.step(action)\n",
    "\n",
    "                # Learning Phase\n",
    "                episode_loss += agent.learn((state,action,reward,nxt_state,done),batch_size)\n",
    "                steps +=1\n",
    "                t+=1\n",
    "\n",
    "                if steps % C == 0: agent.update_target_network()\n",
    "\n",
    "            if i%ep==0: print(f\"Episode:{i} Score:{env.score} Moves:{env.move_count} Loss:{episode_loss/t}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"Training Terminated at Episode {i}\")\n",
    "            return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8df6b1",
   "metadata": {
    "id": "6a8df6b1"
   },
   "source": [
    "## Agent Network Init\n",
    "\n",
    "Architecture: 16->12($Lin$)->6($reLU$)->4($Lin$)\n",
    "\n",
    "HyperParameters: `eta = 5e-4, epsilon=0.7,epsilon_min=0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a2b39b",
   "metadata": {
    "id": "49a2b39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\BAO DAT\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch = [16,12,8,4]\n",
    "af = [\"linear\",\"relu\",\"linear\"]\n",
    "agent = DQN(arch,af,eta=5e-4,epsilon=0.7,epsilon_min=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b7ac9",
   "metadata": {
    "id": "b38b7ac9"
   },
   "source": [
    "## Two different Environments\n",
    "\n",
    "env1 = 10x10\n",
    "\n",
    "env2 = 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced01212",
   "metadata": {
    "id": "ced01212"
   },
   "outputs": [],
   "source": [
    "env1 = Environment(max_moves=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191b0c4b",
   "metadata": {
    "id": "191b0c4b"
   },
   "outputs": [],
   "source": [
    "env2 = Environment(20,20,max_moves=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a361a8",
   "metadata": {
    "id": "a7a361a8"
   },
   "source": [
    "## Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e930eea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e930eea",
    "outputId": "6ef3eab5-241d-4079-8afb-df1afae1e5bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;31;41m ! \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\n",
      "\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;35;47m @ \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "Score: 0 Moves: 3 Direction:1\n"
     ]
    }
   ],
   "source": [
    "before_train = play(agent.Q,env1,record=True,walls=.25) # before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cea3d3",
   "metadata": {
    "id": "68cea3d3"
   },
   "source": [
    "### 1) walls 1% (to give more chance to eat fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628fb1ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "628fb1ad",
    "outputId": "4f6abcd7-0500-4cfa-8b2d-dcbc431f3ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:100 Score:8 Moves:50 Loss:1210.0604010009765\n",
      "Episode:200 Score:12 Moves:50 Loss:1185.5406982421875\n",
      "Episode:300 Score:9 Moves:50 Loss:1280.5768978881836\n",
      "Episode:400 Score:2 Moves:27 Loss:1053.5836351182725\n",
      "Episode:500 Score:0 Moves:8 Loss:1215.3612632751465\n"
     ]
    }
   ],
   "source": [
    "train(agent,env1,500,32,C=20,ep=100,walls=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e9b8e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e9b8e2c",
    "outputId": "7e2ae261-701e-432f-b558-6286268efdb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[0;30;40m   \u001b[0m\n",
      "\u001b[1;32;42m ! \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[0;30;40m   \u001b[0m\u001b[1;35;47m @ \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[1;32;42m ! \u001b[0m\n",
      "\u001b[0;30;40m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;32;42m ! \u001b[0m\u001b[1;37;47m   \u001b[0m\u001b[1;37;47m   \u001b[0m\n",
      "Score: 1 Moves: 9 Direction:0\n"
     ]
    }
   ],
   "source": [
    "play(agent.Q,env1,walls=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a6f69",
   "metadata": {
    "id": "f08a6f69"
   },
   "source": [
    "### 2) walls 20% (to learn how to avoid walls and to eat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8a246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01d8a246",
    "outputId": "7c20700e-5f8f-4ff3-c6ad-12f8475d323c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:100 Score:0 Moves:3 Loss:1129.016845703125\n",
      "Episode:200 Score:0 Moves:3 Loss:1101.5572102864583\n",
      "Episode:300 Score:0 Moves:8 Loss:1166.0054626464844\n",
      "Episode:400 Score:0 Moves:2 Loss:854.2424011230469\n",
      "Episode:500 Score:0 Moves:3 Loss:1130.4477132161458\n",
      "Episode:600 Score:0 Moves:4 Loss:886.9776611328125\n",
      "Episode:700 Score:0 Moves:3 Loss:951.89501953125\n",
      "Episode:800 Score:0 Moves:2 Loss:1292.8173828125\n",
      "Episode:900 Score:0 Moves:1 Loss:1298.5020751953125\n",
      "Episode:1000 Score:0 Moves:1 Loss:856.287109375\n",
      "Episode:1100 Score:0 Moves:1 Loss:462.6907958984375\n",
      "Episode:1200 Score:0 Moves:3 Loss:698.6008097330729\n",
      "Episode:1300 Score:2 Moves:15 Loss:619.6556935628255\n",
      "Episode:1400 Score:0 Moves:1 Loss:620.2691650390625\n",
      "Episode:1500 Score:14 Moves:50 Loss:639.981471862793\n",
      "Episode:1600 Score:1 Moves:13 Loss:516.7033503605769\n",
      "Episode:1700 Score:0 Moves:1 Loss:728.6744384765625\n",
      "Episode:1800 Score:3 Moves:13 Loss:632.8446831336388\n",
      "Episode:1900 Score:2 Moves:13 Loss:563.5427668644832\n",
      "Episode:2000 Score:0 Moves:1 Loss:1199.699951171875\n",
      "Episode:2100 Score:0 Moves:2 Loss:582.3803405761719\n",
      "Episode:2200 Score:0 Moves:2 Loss:1208.9573059082031\n",
      "Episode:2300 Score:2 Moves:18 Loss:825.1566246880425\n",
      "Episode:2400 Score:0 Moves:4 Loss:857.2492904663086\n"
     ]
    }
   ],
   "source": [
    "train(agent,env1,4000,42,C=50,ep=100,walls=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a2068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c66a2068",
    "outputId": "4f9d92f4-412f-49ae-f3c3-7f8469b660b3"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env1,walls=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa31bf",
   "metadata": {
    "id": "c7aa31bf"
   },
   "outputs": [],
   "source": [
    "# Saving weights\n",
    "\n",
    "agent.Q.save_weights(\"networks/maze_harvest/Qc1.h5\")\n",
    "agent.Q_target.save_weights(\"networks/maze_harvest/Qtc1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qc4Dfe3ayzqb",
   "metadata": {
    "id": "qc4Dfe3ayzqb"
   },
   "outputs": [],
   "source": [
    "env1.max_moves = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mh_WTGZwysJo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mh_WTGZwysJo",
    "outputId": "86458591-44ce-4ebe-9997-662d8dc24726"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env1,walls=0.2,nds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ec0df",
   "metadata": {
    "id": "b31ec0df"
   },
   "source": [
    "### 3) walls 20%, nds=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7d109",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29a7d109",
    "outputId": "6c5de9ca-46dd-4cfe-b152-ea83f252a70d"
   },
   "outputs": [],
   "source": [
    "train(agent,env1,2000,42,C=50,ep=100,nds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9bc69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42e9bc69",
    "outputId": "5b825ec8-6263-43f0-e64a-542552fff51c"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env1,walls=0.2,nds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1a7a8",
   "metadata": {
    "id": "7db1a7a8"
   },
   "source": [
    "### 4) walls 30% nds= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d2011",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b7d2011",
    "outputId": "a2da7d4a-39e6-4579-a29a-a1c9e5d4e257"
   },
   "outputs": [],
   "source": [
    "train(agent,env1,3000,42,C=50,ep=100,walls=.3,nds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477cb6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d477cb6d",
    "outputId": "e4ef465c-0913-4bf4-838e-f5a5ca6df54e"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env1,walls=0.3,nds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ImE9uzjl7XaN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImE9uzjl7XaN",
    "outputId": "6ff88719-c017-4932-bff2-bd676c58734c"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env1,walls=0.2,nds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70HHFknI7iRn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70HHFknI7iRn",
    "outputId": "a0979bdd-b85a-4fc2-e016-07de7d63bc90"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env2,walls=0.2,nds=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725Jrn5g77L7",
   "metadata": {
    "id": "725Jrn5g77L7"
   },
   "source": [
    "### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VK2TZz_g768N",
   "metadata": {
    "id": "VK2TZz_g768N"
   },
   "outputs": [],
   "source": [
    "agent.Q.load_weights(\"networks/maze_harvest/Qc1.h5\")\n",
    "agent.Q_target.load_weights(\"networks/maze_harvest/Qtc1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ouOb4uUb7xaj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouOb4uUb7xaj",
    "outputId": "864f6055-ef42-4524-ad80-715f53730560"
   },
   "outputs": [],
   "source": [
    "play(agent.Q,env1,walls=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HqXrfMZH7yG7",
   "metadata": {
    "id": "HqXrfMZH7yG7"
   },
   "source": [
    "Next:\n",
    "- train seperate network for nds=True.\n",
    "- sigmoid for first layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35103b3a",
   "metadata": {},
   "source": [
    "Agent Training Notebook V1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
